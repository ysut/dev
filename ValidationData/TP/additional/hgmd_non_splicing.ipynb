{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -n sss python=3.8 && conda activate sss\n",
    "# conda install -y -c bioconda gffutils jupyter tqdm cyvcf2 pathlib2 pandarallel pysam liftover pybedtools\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from Bio.Seq import Seq\n",
    "# from liftover import get_lifter\n",
    "from pathlib2 import Path\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "import gffutils\n",
    "import pysam\n",
    "from cyvcf2 import VCF\n",
    "\n",
    "### Logging setup\n",
    "from logging import getLogger, config\n",
    "import yaml\n",
    "parent_directory = os.path.dirname(os.path.dirname('__file__'))\n",
    "config_path: str = os.path.join(parent_directory, '../../../config/logging.yaml')\n",
    "with open(config_path, 'r') as f:\n",
    "    config.dictConfig(yaml.safe_load(f))\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "########   Initialize and setup pandas methods   ########\n",
    "os.environ['JOBLIB_TEMP_FOLDER'] = '/tmp' \n",
    "pandarallel.initialize(nb_workers=3, progress_bar=False, verbose=0, use_memory_fs=False) \n",
    "tqdm.pandas()\n",
    "\n",
    "import sys\n",
    "try: \n",
    "    __file__\n",
    "    sys.path.append(os.path.join(os.path.dirname('__file__')))\n",
    "except NameError:\n",
    "    Path().resolve()\n",
    "    sys.path.append(os.path.join(Path().resolve(), '../../../'))\n",
    "\n",
    "from libs import utils, preprocess, variantfilter, posparser, splaiparser\n",
    "# from libs import predeffect, scoring\n",
    "from libs import anno_spliceai, anno_clinvar\n",
    "from libs.deco import print_filtering_count\n",
    "from libs import predeffect\n",
    "from libs.scoring import Scoring\n",
    "\n",
    "gencode_gff = '../../../Resources/05_GENCODE_v43lift37/gencode.v43lift37.annotation.sort.gff3.gz'\n",
    "\n",
    "try:\n",
    "    db_anno_gencode = '../../../Resources/06_gffutilsdb/gencode.v43lift37.annotation.gtf.db'\n",
    "    db_anno_intron = '../../../Resources/06_gffutilsdb/gencode.v43lift37.annotation.intron.gtf.db'\n",
    "    db = gffutils.FeatureDB(db_anno_gencode)\n",
    "    db_intron = gffutils.FeatureDB(db_anno_intron)\n",
    "except ValueError:\n",
    "    db_anno_gencode = '/resources/DBs/gencode.v43lift37.annotation.gtf.db'\n",
    "    db_anno_intron = '/resources/DBs/gencode.v43lift37.annotation.intron.gtf.db'\n",
    "    db = gffutils.FeatureDB(db_anno_gencode)\n",
    "    db_intron = gffutils.FeatureDB(db_anno_intron)\n",
    "\n",
    "## Thresholds configuration\n",
    "thresholds_SpliceAI_parser: dict = {\n",
    "    'TH_min_sALDL': 0.02, 'TH_max_sALDL': 0.2, \n",
    "    'TH_min_sAGDG': 0.01, 'TH_max_sAGDG': 0.05,\n",
    "    'TH_min_GExon': 25, 'TH_max_GExon': 500,\n",
    "    'TH_sAG': 0.2, 'TH_sDG': 0.2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splai_vep_vcfs/hgmd_dm/all_DM_chr1.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr10.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr11.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr12.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr13.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr14.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr15.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr16.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr17.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr18.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr19.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr2.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr20.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr21.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr22.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr3.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr4.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr5.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr6.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr7.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr8.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chr9.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chrX.splai.vep.vcf\n",
      "splai_vep_vcfs/hgmd_dm/all_DM_chrY.splai.vep.vcf\n"
     ]
    }
   ],
   "source": [
    "!for raw_vcf in splai_vep_vcfs/hgmd_dm/all_DM_chr*.splai.vep.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chr1\n",
      "Processing chr2\n",
      "Processing chr3\n",
      "Processing chr4\n",
      "Processing chr5\n",
      "Processing chr6\n",
      "Processing chr7\n",
      "Processing chr8\n",
      "Processing chr9\n",
      "Processing chr10\n",
      "Processing chr11\n",
      "Processing chr12\n",
      "Processing chr13\n",
      "Processing chr14\n",
      "Processing chr15\n",
      "Processing chr16\n",
      "Processing chr17\n",
      "Processing chr18\n",
      "Processing chr19\n",
      "Processing chr20\n",
      "Processing chr21\n",
      "Processing chr22\n",
      "Processing chrX\n",
      "Processing chrY\n"
     ]
    }
   ],
   "source": [
    "## Parse VCF to simple input table\n",
    "chr_list = [str(i) for i in range(1, 23)] + ['X', 'Y']\n",
    "\n",
    "for chr in chr_list:\n",
    "    print(f\"Processing chr{chr}\")\n",
    "    raw_vcf: str = f\"splai_vep_vcfs/hgmd_dm/all_DM_chr{chr}.splai.vep.nondel.vcf\"\n",
    "\n",
    "    vcf = VCF(raw_vcf)\n",
    "    header = vcf.header_iter()\n",
    "    for h in header:\n",
    "        try:\n",
    "            h['ID']\n",
    "        except KeyError:\n",
    "            continue\n",
    "        else:\n",
    "            if h['ID'] == 'CSQ':\n",
    "                vep_cols_list = h['Description'].split('Format: ')[1].rstrip('\"').split('|')\n",
    "            elif h['ID'] == 'SpliceAI':\n",
    "                splai_cols_list = h['Description'].split('Format: ')[1].rstrip('\"').split('|')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    vepidx: dict = {col: i for i, col in enumerate(vep_cols_list)}\n",
    "    splaidx: dict = {col: i for i, col in enumerate(splai_cols_list)}\n",
    "\n",
    "    cols = [\n",
    "        'CHROM', 'POS', 'REF', 'ALT', 'GeneSymbol', 'SymbolSource', 'HGNC_ID', \n",
    "        'ENST', 'HGVSc', 'Consequence', 'EXON', 'INTRON', 'Strand',\n",
    "        'DS_AG', 'DS_AL', 'DS_DG', 'DS_DL', 'DP_AG', 'DP_AL', 'DP_DG', 'DP_DL', 'MaxSpliceAI'\n",
    "    ]\n",
    "\n",
    "    # print(vepidx)\n",
    "\n",
    "    df: pd.DataFrame = pd.DataFrame(columns=cols)\n",
    "    for v in VCF(raw_vcf):\n",
    "        vep: list = v.INFO.get('CSQ').split('|')\n",
    "\n",
    "        # Get SpliceAI scores\n",
    "        if v.INFO.get('SpliceAI'):\n",
    "            splai: list = v.INFO.get('SpliceAI').split(',')[0].split('|')\n",
    "        else:\n",
    "            splai = ['NA'] * len(splai_cols_list)\n",
    "\n",
    "        # Get HGVSc from VEP\n",
    "        try:\n",
    "            hgvsc = re.search('(?<=:).*',vep[vepidx['HGVSc']])[0]\n",
    "        except TypeError:\n",
    "            hgvsc = \"NA\"\n",
    "\n",
    "        # Convert strand to +/- \n",
    "        strand = lambda s: '+' if s == '1' else '-'\n",
    "\n",
    "        # Get max SpliceAI scores\n",
    "        ds_ag: float = splai[splaidx['DS_AG']]\n",
    "        ds_al: float = splai[splaidx['DS_AL']]\n",
    "        ds_dg: float = splai[splaidx['DS_DG']]\n",
    "        ds_dl: float = splai[splaidx['DS_DL']]\n",
    "        if splai[splaidx['DP_AG']] == 'NA':\n",
    "            maxsplai: str = \"NA\"\n",
    "        maxsplai: float = max(ds_ag, ds_al, ds_dg, ds_dl)\n",
    "\n",
    "        # Add df row\n",
    "        df = pd.concat([df, pd.DataFrame([[\n",
    "            v.CHROM, v.POS, v.REF, v.ALT[0], \n",
    "            vep[vepidx['SYMBOL']], vep[vepidx['SYMBOL_SOURCE']], vep[vepidx['HGNC_ID']], \n",
    "            vep[vepidx['Feature']], hgvsc, vep[vepidx['Consequence']], \n",
    "            vep[vepidx['EXON']], vep[vepidx['INTRON']],\n",
    "            strand(vep[vepidx['STRAND']]), \n",
    "            ds_ag, ds_al, ds_dg, ds_dl,\n",
    "            splai[splaidx['DP_AG']], splai[splaidx['DP_AL']], \n",
    "            splai[splaidx['DP_DG']], splai[splaidx['DP_DL']],\n",
    "            maxsplai\n",
    "        ]], columns=cols)], ignore_index=True)\n",
    "\n",
    "        # if hgvsc == \"NA\":\n",
    "        #     logger.warning(f\"[{v.CHROM}:{v.POS}] HGVSc not found\")\n",
    "        # if maxsplai == \"NA\":\n",
    "        #     logger.warning(f\"[{v.CHROM}:{v.POS}] SpliceAI scores not found\")\n",
    "\n",
    "    # ALLELE|SYMBOL|DS_AG|DS_AL|DS_DG|DS_DL|DP_AG|DP_AL|DP_DG|DP_DL\n",
    "    # CHROM, POS, REF, ALT, GeneSymbol, NCBI_ID, ENST, ExonIntronNumbers, FLAGS, SYMBOL_SOURCE|\n",
    "\n",
    "    df.to_pickle(f\"splai_vep_vcfs/hgmd_dm/all_DM_chr{chr}.splai.vep.nondel.vcf.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20701\n",
      "20687\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_pickle('splai_vep_vcfs/hgmd_dm/all_DM_chr1.splai.vep.pkl')\n",
    "print(len(df))\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:09:49 [INFO   ] (__main__) - chr1\n",
      "20588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20574/20574 [07:13<00:00, 47.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:17:02 [INFO   ] (__main__) - chr2\n",
      "21002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20983/20983 [06:52<00:00, 50.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:23:55 [INFO   ] (__main__) - chr3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13720/13720 [02:33<00:00, 89.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:26:29 [INFO   ] (__main__) - chr4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6497/6497 [00:52<00:00, 123.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:27:22 [INFO   ] (__main__) - chr5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10041/10041 [01:41<00:00, 98.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:29:04 [INFO   ] (__main__) - chr6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9220/9220 [01:48<00:00, 84.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:30:52 [INFO   ] (__main__) - chr7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11454/11454 [02:02<00:00, 93.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:32:54 [INFO   ] (__main__) - chr8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7177/7177 [00:55<00:00, 128.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:33:50 [INFO   ] (__main__) - chr9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9064/9064 [01:13<00:00, 122.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:35:04 [INFO   ] (__main__) - chr10\n",
      "7061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7051/7051 [01:06<00:00, 106.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:36:10 [INFO   ] (__main__) - chr11\n",
      "17276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17246/17246 [03:28<00:00, 82.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:39:39 [INFO   ] (__main__) - chr12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11582/11582 [02:01<00:00, 95.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:41:41 [INFO   ] (__main__) - chr13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7769/7769 [00:23<00:00, 332.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:42:04 [INFO   ] (__main__) - chr14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6058/6058 [00:48<00:00, 124.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:42:53 [INFO   ] (__main__) - chr15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9484/9484 [01:03<00:00, 149.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:43:57 [INFO   ] (__main__) - chr16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13776/13776 [01:36<00:00, 142.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:45:34 [INFO   ] (__main__) - chr17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18378/18378 [06:17<00:00, 48.64it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:51:52 [INFO   ] (__main__) - chr18\n",
      "3767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3761/3761 [00:13<00:00, 278.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:52:05 [INFO   ] (__main__) - chr19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11075/11075 [01:43<00:00, 106.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:53:49 [INFO   ] (__main__) - chr20\n",
      "4363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4360/4360 [00:21<00:00, 204.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:54:10 [INFO   ] (__main__) - chr21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2332/2332 [00:06<00:00, 343.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:54:17 [INFO   ] (__main__) - chr22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4092/4092 [00:19<00:00, 209.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:54:37 [INFO   ] (__main__) - chrX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31016/31016 [04:19<00:00, 119.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/20 08:58:56 [INFO   ] (__main__) - chrY\n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:00<00:00, 744.95it/s]\n"
     ]
    }
   ],
   "source": [
    "#### Very slow process ####\n",
    "# Annotate ENST Full ID for fetching variant information from GENCODE database\n",
    "\n",
    "for chr in chr_list:\n",
    "\tlogger.info(f\"chr{chr}\")\n",
    "\tdf = pd.read_pickle(f'splai_vep_vcfs/hgmd_dm/all_DM_chr{chr}.splai.vep.nondel.vcf.pkl')\n",
    "\tprint(len(df))\n",
    "\tdf.drop_duplicates(inplace=True)\n",
    "\tdf['ENST_Full'] = df.progress_apply(posparser.fetch_enst_full, db=db, axis=1)\n",
    "\tdf.to_pickle(f'splai_vep_vcfs/hgmd_dm/all_DM_chr{chr}.splai.vep.nondel.vcf.enst.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ここから解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chr in chr_list:\n",
    "    df = pd.read_pickle(f'splai_vep_vcfs/hgmd_dm/all_DM_chr{chr}.splai.vep.nondel.vcf.enst.pkl')\n",
    "\n",
    "    logger.info('Classify \"Canonical\" splice site or \"Non-canonical\" splice site...')\n",
    "    df = posparser.classifying_canonical(df)\n",
    "\n",
    "    logger.info('Calculate the distance to the nearest splice site in intron variant...')\n",
    "    df['IntronDist'] = df.progress_apply(\n",
    "        posparser.signed_distance_to_exon_boundary, \n",
    "        db=db, db_intron=db_intron, axis=1)\n",
    "\n",
    "    tbx_anno = pysam.TabixFile(gencode_gff)\n",
    "    df['exon_loc'] = df.progress_apply(\n",
    "        posparser.calc_exon_loc, tabixfile=tbx_anno, enstcolname='ENST', axis=1)\n",
    "    df = pd.concat([df, df['exon_loc'].str.split(':', expand=True)], axis=1)\n",
    "    df.rename(columns={0: 'ex_up_dist', 1: 'ex_down_dist'}, inplace=True)\n",
    "    df.drop(columns=['exon_loc'], inplace=True)\n",
    "\n",
    "    #2-2. Select minimum distance from upstream distance and downstream distance\n",
    "    df['exon_pos'] = df.parallel_apply(posparser.select_exon_pos, axis=1)\n",
    "    #2-3. Relative exon location\n",
    "    df['prc_exon_loc'] = df.parallel_apply(posparser.calc_prc_exon_loc, axis=1)\n",
    "\n",
    "    #2-4. Decision exonic splice sites (1 nt in acceptor site or 3 nts on Donor site)\n",
    "    df['exon_splice_site'] = df.parallel_apply(posparser.extract_splicing_region, axis=1)\n",
    "\n",
    "    #3.   Additional Splicing information\n",
    "    logger.info('Annotating splicing information...')\n",
    "    #3-1. Annotate splicing type ('Exonic Acceptor' etc.)\n",
    "    df['SpliceType'] = df.parallel_apply(posparser.select_donor_acceptor, axis=1)\n",
    "\n",
    "    #5.   Annotate ClinVar varaints interpretations\n",
    "    logger.info('Annotating ClinVar varaints interpretations...')\n",
    "    clinvar_file = '../../../Resources/03_ClinVar/variant_summary.snv.grch37.germline.criteria.sort.bed.gz'\n",
    "    tbx_clinvar = pysam.TabixFile(clinvar_file)\n",
    "    df['clinvar_same_pos'] = df.progress_apply(\n",
    "        anno_clinvar.anno_same_pos_vars, tabixfile=tbx_clinvar, axis=1)\n",
    "    df['clinvar_same_motif'] = df.progress_apply(\n",
    "        anno_clinvar.anno_same_motif_vars, tabixfile=tbx_clinvar, axis=1)\n",
    "\n",
    "    logger.info('Parsing SpliceAI results...')\n",
    "    logger.info('Annotating Exon/Intron position information...')\n",
    "    df['ExInt_INFO'] = df.progress_apply(\n",
    "        splaiparser.calc_exint_info, db=db, db_intron=db_intron, axis=1)\n",
    "\n",
    "    #6-3. Predict splicing effects\n",
    "    df['Pseudoexon'] = df.progress_apply(\n",
    "        splaiparser.pseudoexon_activation,\n",
    "        thresholds=thresholds_SpliceAI_parser, \n",
    "        db_intron=db_intron,\n",
    "        axis=1)\n",
    "\n",
    "    df['Part_IntRet'] = df.parallel_apply(\n",
    "        splaiparser.partial_intron_retention,\n",
    "        thresholds=thresholds_SpliceAI_parser, \n",
    "        axis=1)\n",
    "\n",
    "    df['Part_ExDel'] = df.parallel_apply(\n",
    "        splaiparser.partial_exon_deletion,\n",
    "        thresholds=thresholds_SpliceAI_parser, \n",
    "        axis=1)\n",
    "\n",
    "    df['Exon_skipping'] = df.parallel_apply(\n",
    "        splaiparser.exon_skipping, \n",
    "        thresholds=thresholds_SpliceAI_parser, \n",
    "        axis=1)\n",
    "                                            \n",
    "    df['Int_Retention'] = df.parallel_apply(\n",
    "        splaiparser.intron_retention, \n",
    "        thresholds=thresholds_SpliceAI_parser, \n",
    "        axis=1)\n",
    "\n",
    "    df['multiexs'] = df.parallel_apply(\n",
    "        splaiparser.multi_exon_skipping, \n",
    "        thresholds=thresholds_SpliceAI_parser, \n",
    "        axis=1)\n",
    "\n",
    "    # df = pd.read_pickle('splai_vep_vcfs/hgmd_dm/all_DM_chr1.splai.vep.enst.introndist.exintinfo.splicing2.pkl')\n",
    "    #7.   Annotate aberrant splicing size (bp)\n",
    "    logger.info('Annotating aberrant splicing size (bp)...')\n",
    "    #7-1. Annotate size of \n",
    "    df['Size_Part_ExDel'] = df.parallel_apply(\n",
    "        splaiparser.anno_partial_exon_del_size, \n",
    "        thresholds=thresholds_SpliceAI_parser, \n",
    "        axis=1)\n",
    "\n",
    "    #7-3. Annotate size of partial intron retention\n",
    "    df['Size_Part_IntRet'] = df.parallel_apply(\n",
    "        splaiparser.anno_partial_intron_retention_size, \n",
    "        thresholds=thresholds_SpliceAI_parser,\n",
    "        axis=1)\n",
    "\n",
    "    #7-2. Annotate size of pseudoexon\n",
    "    df['Size_pseudoexon'] = df.parallel_apply(\n",
    "        splaiparser.anno_gained_exon_size, \n",
    "        thresholds=thresholds_SpliceAI_parser, \n",
    "        axis=1)\n",
    "\n",
    "    #7-4. Annotate size of intron retention\n",
    "    df['Size_IntRet'] = df.parallel_apply(\n",
    "        splaiparser.anno_intron_retention_size, \n",
    "        thresholds=thresholds_SpliceAI_parser,\n",
    "        axis=1)\n",
    "\n",
    "    #7-5. Annotate size of exon skipping\n",
    "    df['Size_skipped_exon'] = df.parallel_apply(\n",
    "        splaiparser.anno_skipped_exon_size, \n",
    "        thresholds=thresholds_SpliceAI_parser,\n",
    "        axis=1)\n",
    "\n",
    "    df['variant_id'] = df['CHROM'].astype(str) + '-' \\\n",
    "        + df['POS'].astype(str) + '-' + df['REF'] + '-' + df['ALT']\n",
    "\n",
    "    #8.   Evaluate splicing effects\n",
    "    logger.info('Predicting CDS change...')\n",
    "    #8-1. Predict CDS change\n",
    "    df['CDS_Length'] = df.progress_apply(predeffect.calc_cds_len, db=db, axis=1)\n",
    "    df['is_10%_truncation'] = df.progress_apply(predeffect.calc_cds_len_shorten, axis=1)\n",
    "\n",
    "    #8-2. Determine if the gene is included in eLoFs genes\n",
    "    df['is_eLoF'] = df.parallel_apply(predeffect.elofs_judge, axis=1)\n",
    "\n",
    "    #8-3. Determine causing NMD or not\n",
    "    df['is_NMD_at_Canon'] = df.parallel_apply(predeffect.nmd_judge, axis=1)\n",
    "\n",
    "    #8-4. Frame check\n",
    "    # Covert to str (Cannot predict splicing event) to np.nan\n",
    "\n",
    "\n",
    "    cannot_predict: str = 'Cannot predict splicing event'\n",
    "    df['Size_Part_ExDel'] = df['Size_Part_ExDel'].replace(cannot_predict, np.nan)\n",
    "    df['Size_Part_IntRet'] = df['Size_Part_IntRet'].replace(cannot_predict, np.nan)\n",
    "    df['Size_pseudoexon'] = df['Size_pseudoexon'].replace(cannot_predict, np.nan)\n",
    "    df['Size_IntRet'] = df['Size_IntRet'].replace(cannot_predict, np.nan)\n",
    "    df['Size_skipped_exon'] = df['Size_skipped_exon'].replace(cannot_predict, np.nan)\n",
    "\n",
    "    df['is_Frameshift_Part_ExDel'] = df['Size_Part_ExDel'].parallel_apply(\n",
    "        predeffect.frame_check)\n",
    "    df['is_Frameshift_Part_IntRet'] = df['Size_Part_IntRet'].parallel_apply(\n",
    "        predeffect.frame_check)\n",
    "    df['is_Frameshift_pseudoexon'] = df['Size_pseudoexon'].parallel_apply(\n",
    "        predeffect.frame_check)\n",
    "    df['is_Frameshift_IntRet'] = df['Size_IntRet'].parallel_apply(\n",
    "        predeffect.frame_check)\n",
    "    df['is_Frameshift_skipped_exon'] = df['Size_skipped_exon'].parallel_apply(\n",
    "        predeffect.frame_check)\n",
    "    df['is_Frameshift'] = df[['is_Frameshift_Part_ExDel', \n",
    "                            'is_Frameshift_Part_IntRet', \n",
    "                            'is_Frameshift_pseudoexon', \n",
    "                            'is_Frameshift_IntRet', \n",
    "                            'is_Frameshift_skipped_exon'\n",
    "                            ]].any(axis=1)\n",
    "\n",
    "    #9.   CCRs\n",
    "    logger.info('Annotating CCRs info...')\n",
    "    #9-1. Annotate truncated regions \n",
    "    df['skipped_region'] = df.parallel_apply(\n",
    "        splaiparser.anno_skipped_regions, axis=1)\n",
    "    df['deleted_region'] = df.parallel_apply(\n",
    "        splaiparser.anno_deleted_regions, \n",
    "        thresholds=thresholds_SpliceAI_parser, axis=1)\n",
    "\n",
    "    #9-2. Intersect with CCRs\n",
    "    logger.info('Annotate CCR score')\n",
    "    df = predeffect.anno_ccr_score(df)\n",
    "\n",
    "    df.to_pickle(f'splai_vep_vcfs/hgmd_dm/all_DM_chr{chr}.splai.vep.nondel.vcf.enst.prescore.pkl')\n",
    "    logger.info(f\"Comleted chr{chr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(f'splai_vep_vcfs/hgmd_dm/all_DM_chr{chr}.splai.vep.nondel.vcf.enst.prescore.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/10/21 02:15:04 [INFO   ] (__main__) - Annotating Screening scores...\n"
     ]
    }
   ],
   "source": [
    "df: pd.DataFrame = pd.concat([pd.read_pickle(f'splai_vep_vcfs/hgmd_dm/all_DM_chr{chr}.splai.vep.nondel.vcf.enst.prescore.pkl') for chr in chr_list])\n",
    "\n",
    "#10.  Scoring\n",
    "sccore_ths = {'clinvar_same_pos': 2,     \n",
    "                'clinvar_same_motif': 1,\n",
    "                'clinvar_else': 0,\n",
    "                'non_canon_splai_lte_0.1_outside': -3,\n",
    "                'non_canon_splai_lte_0.1_other': -2,\n",
    "                'non_canon_splai_bet_0.1_0.2': 1,\n",
    "                'non_canon_splai_gte_0.2': 2,\n",
    "                'canon_strong': 6, \n",
    "                'canon_moderate': 5, \n",
    "                'frameshift_nmd_eloF': 7, \n",
    "                'frameshift_nmd_not_eloF': 3,\n",
    "                'canon_splai_lte_0.1': -3,\n",
    "                'canon_splai_bet_0.1_0.2': -1,\n",
    "                'canon_splai_gte_0.2': 0}\n",
    "scoring = Scoring(ths=sccore_ths)\n",
    "\n",
    "logger.info('Annotating Screening scores...')\n",
    "df.rename(columns={'MaxSpliceAI': 'maxsplai'}, inplace=True)\n",
    "df['insilico_screening'] = df.parallel_apply(scoring.insilico_screening, axis=1)\n",
    "df['clinvar_screening'] = df.parallel_apply(scoring.clinvar_screening, axis=1)\n",
    "df['PriorityScore'] = df.parallel_apply(scoring.calc_priority_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('splai_vep_vcfs/hgmd_dm/all_DM_chr1-22.splai.vep.nondel.vcf.enst.scored.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('splai_vep_vcfs/hgmd_dm/all_DM_chr1-22.splai.vep.nondel.vcf.enst.scored.pkl')\n",
    "df = df[['variant_id', 'CHROM', 'POS', 'HGVSc', 'maxsplai', 'clinvar_screening', 'insilico_screening', 'PriorityScore']]\n",
    "df['variant_id2'] = df['CHROM'].astype(str) + '-' + df['POS'].astype(str) + '-' + df['HGVSc']\n",
    "df = df.loc[df['PriorityScore'] != 'Not available']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 253018 DM mutations are found in allmut.\n"
     ]
    }
   ],
   "source": [
    "all_mut_default_colnames: list = [\n",
    "    \"disase\", \"gene\", \"chrom\", \"genename\", \"gdbid\", \"omimid\", \"amino\", \n",
    "    \"deletion\", \"insertion\", \"codon\", \"codonAff\", \"descr\", \"refseq\", \"hgvs\", \n",
    "    \"hgvsAll\", \"dbsnp\", \"chromosome\", \"startCoord\", \"endCoord\", \n",
    "    \"expected_inheritance\", \"gnomad_AC\", \"gnomad_AF\", \"gnomad_AN\", \"tag\", \n",
    "    \"dmsupport\", \"rankscore\", \"mutype\", \"author\", \"title\", \"fullname\", \n",
    "    \"allname\", \"vol\", \"page\", \"year\", \"pmid\", \"pmidAll\", \"reftag\", \"comments\", \n",
    "    \"acc_num\", \"new_date\", \"base\", \"clinvarID\", \"clinvar_clnsig\"\n",
    "]\n",
    "allmut: pd.DataFrame = pd.read_csv(\n",
    "    'allmut.csv', sep=';', encoding='cp1252', names=all_mut_default_colnames, \n",
    "    skiprows=1,low_memory=False)\n",
    "\n",
    "allmut = allmut[\n",
    "    [\"gene\", \"genename\", \"mutype\", \"clinvar_clnsig\", \"tag\",\n",
    "     \"refseq\", \"hgvs\", \"hgvsAll\", \"chromosome\", \"startCoord\", \"endCoord\", \n",
    "     \"amino\", \"deletion\", \"insertion\", \"expected_inheritance\", \"gnomad_AF\"]]\n",
    "\n",
    "# Drop non-numeric values in 'startCoord'\n",
    "allmut = allmut.dropna(subset=['startCoord'])\n",
    "\n",
    "# Drop duplicates in 'chrom', 'startCoord', and 'endCoord'\n",
    "allmut = allmut.drop_duplicates(subset=['chromosome', 'startCoord', 'endCoord'])\n",
    "\n",
    "# Extract tag == \"DM\" from allmut\n",
    "allmut_dm = allmut[allmut.tag == \"DM\"].copy()\n",
    "print(f\"A total of {len(allmut_dm)} DM mutations are found in allmut.\")\n",
    "\n",
    "allmut_dm['startCoord'] = allmut_dm['startCoord'].astype(int)\n",
    "allmut_dm = allmut_dm.rename(columns={'chromosome': 'CHROM', 'startCoord': 'POS_hg38'})\n",
    "# allmut_dm['variant_id2'] = allmut_dm['chromosome'].astype(str) + '-' \\\n",
    "# \t+ allmut_dm['startCoord'].astype(str) + '-' + allmut_dm['hgvs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 231981 DM mutations are found in allmut with MAF 0.\n",
      "A total of 154107 DM mutations are found in allmut with MAF 0 and non-deletion or non-insertion.\n",
      "Splicing_DM: 22178, Non-splicing_DM: 131929\n"
     ]
    }
   ],
   "source": [
    "# Fillna with empty string in \"gnomad_AF\" colmun in allmut_dm\n",
    "# Extratct MAF 0 from allmut_dm\n",
    "allmut_dm['gnomad_AF'].fillna(0, inplace=True)\n",
    "allmut_dm_maf0 = allmut_dm[allmut_dm['gnomad_AF'] == 0].copy()\n",
    "print(f\"A total of {len(allmut_dm_maf0)} DM mutations are found in allmut with MAF 0.\")\n",
    "\n",
    "# Extract non-deletion or non-insertion from allmut_dm\n",
    "allmut_dm_maf0_snv = allmut_dm_maf0[(allmut_dm_maf0['deletion'].isnull()) & (allmut_dm_maf0['insertion'].isnull())]\n",
    "print(f\"A total of {len(allmut_dm_maf0_snv)} DM mutations are found in allmut with MAF 0 and non-deletion or non-insertion.\")\n",
    "\n",
    "# Extract the mutation type from the mutype column\n",
    "splice_mutations = allmut_dm_maf0_snv[allmut_dm_maf0_snv[\"mutype\"].str.contains(\"splice\")].copy()\n",
    "non_splice_mutations = allmut_dm_maf0_snv[~allmut_dm_maf0_snv[\"mutype\"].str.contains(\"splice\")]\n",
    "print(f\"Splicing_DM: {len(splice_mutations)}, Non-splicing_DM: {len(non_splice_mutations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     converted \u001b[38;5;241m=\u001b[39m _liftover_to_hg19(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCHROM\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOS_hg38\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m non_splice_mutations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOS_hg19\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnon_splice_mutations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43manno_hg19_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sss/lib/python3.8/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/sss/lib/python3.8/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sss/lib/python3.8/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniforge3/envs/sss/lib/python3.8/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[88], line 13\u001b[0m, in \u001b[0;36manno_hg19_pos\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manno_hg19_pos\u001b[39m(row):\n\u001b[0;32m---> 13\u001b[0m     converted \u001b[38;5;241m=\u001b[39m \u001b[43m_liftover_to_hg19\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCHROM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOS_hg38\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[88], line 5\u001b[0m, in \u001b[0;36m_liftover_to_hg19\u001b[0;34m(chrom, pos)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_liftover_to_hg19\u001b[39m(chrom, pos):\n\u001b[0;32m----> 5\u001b[0m     converter \u001b[38;5;241m=\u001b[39m \u001b[43mget_lifter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhg38\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhg19\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     result \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mquery(chrom, pos)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[0;32m~/miniforge3/envs/sss/lib/python3.8/site-packages/liftover/lifter.py:39\u001b[0m, in \u001b[0;36mget_lifter\u001b[0;34m(target, query, cache, one_based, chain_server)\u001b[0m\n\u001b[1;32m     36\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain_server\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/goldenpath/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/liftOver/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbasename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     37\u001b[0m     download_file(url, chain_path)\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChainFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mone_based\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Convert startCoord to hg19\n",
    "from liftover import get_lifter\n",
    "\n",
    "def _liftover_to_hg19(chrom, pos):\n",
    "    converter = get_lifter('hg38', 'hg19')\n",
    "    result = converter.query(chrom, pos)\n",
    "    if result:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def anno_hg19_pos(row):\n",
    "    converted = _liftover_to_hg19(row['CHROM'], row['POS_hg38'])\n",
    "    return converted[1]\n",
    "\n",
    "non_splice_mutations['POS_hg19'] = non_splice_mutations.apply(anno_hg19_pos, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_splice_mutations.to_csv('non_splice_mutations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_splice_mutations['variant_id2'] = non_splice_mutations['chromosome'].astype(str) + '-' \\\n",
    "\t+ non_splice_mutations['startCoord'].astype(str) + '-' + non_splice_mutations['hgvs']\n",
    "\n",
    "non_splice_mutations_variants: list = non_splice_mutations['variant_id2'].tolist()\n",
    "df['is_non_splice_DM'] = df['variant_id2'].isin(non_splice_mutations_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mitertuples():\n\u001b[0;32m----> 2\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariant_id2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnon_splice_mutations_variants\u001b[49m:\n\u001b[1;32m      3\u001b[0m \t\t\u001b[38;5;66;03m# df.at[row.Index, 'is_non_splice_DM'] = True\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \t\t\u001b[38;5;28mprint\u001b[39m(row\u001b[38;5;241m.\u001b[39mvariant_id2)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for row in df.itertuples():\n",
    "\tif row.variant_id2 in non_splice_mutations_variants:\n",
    "\t\t# df.at[row.Index, 'is_non_splice_DM'] = True\n",
    "\t\tprint(row.variant_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250733"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['variant_id2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510804"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allmut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _liftover_to_hg19(chrom, pos):\n",
    "    converter = get_lifter('hg38', 'hg19')\n",
    "    result = converter.query(chrom, pos)\n",
    "    if result:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def anno_vars_id(row):\n",
    "    variant_id = f'{row[\"CHROM\"]}:{row[\"POS_hg19\"]}-{row[\"REF\"]}-{row[\"ALT\"]}'\n",
    "    return variant_id\n",
    "\n",
    "def anno_hg19_pos(row):\n",
    "    converted = _liftover_to_hg19(row['CHROM'], row['POS_hg38'])\n",
    "    return converted[1]\n",
    "\n",
    "def remove_dot_ver(x):\n",
    "    if x == '.':\n",
    "        pass\n",
    "    else:\n",
    "        return re.match(r'[a-zA-Z_]+\\d+', x).group()\n",
    "    \n",
    "def remove_non_canon(x):\n",
    "    if x in enst_set:\n",
    "        return True\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def create_refalt(row, nt):\n",
    "    if row['Strand'] == '+':\n",
    "        return row[nt]\n",
    "    elif row['Strand'] == '-':\n",
    "        return str(Seq(row[nt]).complement())\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonlist = '/Github/Projects/DeNovo/data/CanonicalTranscripts_COMP/CanonicalTranscripts.exoncount.tsv'\n",
    "refseq = '/work/CanonicalTrasncripts/gencode.v43lift37.metadata.RefSeq.gz'\n",
    "\n",
    "df_canon = pd.read_table(canonlist, header=0)\n",
    "df_canon = df_canon[(df_canon['ENST'] != 'ENST00000649912')\n",
    "                    & (df_canon['ENST'] != 'ENST00000609375')]\n",
    "df_enst = df_canon.drop_duplicates(subset='ENST')\n",
    "enst_set = set(df_enst['ENST'])\n",
    "df_refseq = pd.read_table(refseq, header=None, \n",
    "                          names=['ENST_refseq', 'RefSeq_RNA', 'RefSeq_Pro'])\n",
    "df_refseq.fillna(value='.', inplace=True)\n",
    "\n",
    "df_refseq['ENST_refseq'] = df_refseq['ENST_refseq'].apply(remove_dot_ver)\n",
    "df_refseq['RefSeq_RNA'] = df_refseq['RefSeq_RNA'].apply(remove_dot_ver)\n",
    "df_refseq['RefSeq_Pro'] = df_refseq['RefSeq_Pro'].apply(remove_dot_ver)\n",
    "\n",
    "df_refseq['is_Canonical'] =  df_refseq['ENST_refseq'].apply(remove_non_canon)\n",
    "df_refseq_canon = df_refseq[df_refseq['is_Canonical'] == True].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading HGMD splicing variants list (tsv)\n",
    "hgmd_file = '/Github/MyProjects/DeNovo/data/ValidationData/Positive/allmut.trim.colfixed.maf0.tsv.txt'\n",
    "df = pd.read_table(hgmd_file, header=0)\n",
    "\n",
    "# Pre-processing\n",
    "df = df.dropna(subset=['startCoord'])\n",
    "df['startCoord'] = df['startCoord'].astype(int)\n",
    "df['refseq'] = df['refseq'].apply(remove_dot_ver)\n",
    "\n",
    "# Extract REF and ALT from HGVS descriptions\n",
    "sr_alt_nt = df['hgvs'].str[-1:].rename('alt_nt')\n",
    "sr_ref_nt = df['hgvs'].str[-3:-2].rename('ref_nt')\n",
    "df = pd.concat([df, sr_ref_nt, sr_alt_nt], axis=1)\n",
    "\n",
    "# Insert cols as VCF\n",
    "df.loc[:,'ID'] = '.'\n",
    "df.loc[:,'QUAL'] = '.'\n",
    "df.loc[:,'FILTER'] = '.'\n",
    "df.loc[:,'INFO'] = '.'\n",
    "\n",
    "# Annotate ENST IDs\n",
    "df = pd.merge(df, df_enst, how='left', \n",
    "              left_on='gene', right_on='GeneSymbol')\n",
    "\n",
    "# Rename cols for downstream processing\n",
    "df = df.rename(columns={'CHROM': 'Chr',\n",
    "                        'chromosome': 'CHROM', \n",
    "                        'startCoord': 'POS_hg38'})\n",
    "\n",
    "# Create REF and ALT columns\n",
    "df['REF'] = df.apply(create_refalt, nt='ref_nt', axis=1)\n",
    "df['ALT'] = df.apply(create_refalt, nt='alt_nt', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liftover to hg19\n",
    "df['POS_hg19'] = df.apply(anno_hg19_pos, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2 = df2.astype({'POS_hg19': str})\n",
    "\n",
    "# Annotate variant IDs\n",
    "df2['variant_id'] = df2.apply(anno_vars_id, axis=1)\n",
    "\n",
    "# Extract columns for VCF\n",
    "df_19 = df2[['CHROM', 'POS_hg19', \n",
    "             'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']]\n",
    "df_38 = df2[['CHROM', 'POS_hg38', \n",
    "             'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_19 = df_19.dropna(subset=['REF'])\n",
    "df_38 = df_38.dropna(subset=['REF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output as VCF\n",
    "df_19.to_csv('./patho.hg19.vcf', sep='\\t', index=False, header=False)\n",
    "df_38.to_csv('./patho.hg38.vcf', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenate header and variant list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../header_for_VCF.tsv ./patho.hg19.vcf > patho.hg19.header.vcf\n",
    "!cat ../header_for_VCF.tsv ./patho.hg38.vcf > patho.hg38.header.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strand</th>\n",
       "      <th>ref_nt</th>\n",
       "      <th>REF</th>\n",
       "      <th>alt_nt</th>\n",
       "      <th>ALT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10553</th>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10554</th>\n",
       "      <td>+</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10555</th>\n",
       "      <td>-</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10556</th>\n",
       "      <td>-</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10557</th>\n",
       "      <td>+</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10558 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Strand ref_nt   REF alt_nt   ALT\n",
       "0          +      A     A      G     G\n",
       "1          -      T     A      G     C\n",
       "2          -      G     C      A     T\n",
       "3          +      A     A      G     G\n",
       "4          -      A     T      G     C\n",
       "...      ...    ...   ...    ...   ...\n",
       "10553    NaN      G  None      A  None\n",
       "10554      +      G     G      A     A\n",
       "10555      -      G     C      A     T\n",
       "10556      -      G     C      A     T\n",
       "10557      +      G     G      A     A\n",
       "\n",
       "[10558 rows x 5 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Strand', 'ref_nt', 'REF', 'alt_nt', 'ALT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =df2[['gene', 'gdbid', 'omimid', 'amino', 'codon', 'codonAff', 'descr',\n",
    "       'refseq', 'hgvs', 'CHROM', 'POS_hg38', 'endCoord', \n",
    "       'expected_inheritance', 'dmsupport', 'mutype', 'acc_num', 'new_date', \n",
    "       'clinvarID', 'clinvar_clnsig', 'Chr', 'Start', 'End', 'Strand', \n",
    "       'GeneSymbol', 'HGNC_ID', 'ENSG', 'ENST', 'GeneType', 'Tag', \n",
    "       'REF', 'ALT', 'POS_hg19', 'variant_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('./patho2.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#解除後の賃料はどうなっているか"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
